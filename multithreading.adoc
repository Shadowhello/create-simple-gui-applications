[#multithreading]
== Multithreading

As you start to build more complex applications, you may come across
problems where long-running tasks "lock up" your interface.

The event loop started by calling `.exec_()` on your `QApplication`
object and runs within the same thread as your Python code. The thread
which runs this event loop — commonly  referred to as the _GUI thread_ —
also handles all window communication with the host operating system.

By default, any execution triggered by the event loop will also run
synchronously within this thread. In practise this means that any time
your PyQt application spends _doing something_ in your code, window
communication and GUI interaction are frozen.

If what you're doing is simple, and returns control to the GUI loop
quickly, this freeze will be imperceptible to the user. However, if you
need to perform longer-running tasks, for example opening/writing a
large file, downloading some data, or rendering some complex image,
there are going to be problems. To your user the application will appear
to be unresponsive (because it is). Because your app is no longer
communicating with the OS, on MacOS X if you click on your app you will
see the spinning wheel of death. And, _nobody_ wants that.

The solution is simple: get your work out of the _GUI_ thread and into
another . PyQt (via Qt) provides an straightforward interface to
do exactly that.

=== Preparation

To demonstrate multi-threaded execution we need an application to work
with. Below is a minimal stub application for PyQt which will allow us
to demonstrate multithreading, and see the outcome in action. Simply
copy and paste this into a new file, and save it with an  appropriate
filename like `multithread.py`. The remainder of the code will be added
to this file (there is also a complete working example at the bottom if
you're impatient).

[source,python]
----
include::code/multithreading_1.py[]
----

Run the file as normal:

[.terminal]
----
python3 multithread.py
----

You should see a demonstration window with a number counting upwards.
This a generated by a simple recurring time, firing once per second.
Think of this as our _event loop indicator_, a simple way to let us
known that out application is ticking over normally. There is also a
button with the word *"DANGER!"*. Push it.

.Push the button.
image::danger-button.png[scaledwidth=50%,align="center"]

You'll notice that each time you push the button the counter stops
ticking and your application freezes entirely. On Windows you may see
the window turn pale, indicating it is not responding, while on a Mac
you may see the spinning wheel of death.

=== The dumb approach

What appears as a _frozen interface_ is in fact caused by the Qt event
loop being blocked from processing (and responding to) window events.
Your clicks on the window as still registered by the host OS and sent
to your application, but because it's sat in your big ol' lump of code
(`time.sleep`), it can't accept or react to them. Your application does
not respond to the OS and it interprets this as a frozen application.

The simplest way get around this is to
accept events from within your code. This allows Qt to continue to
respond to the host OS and your application
will stay responsive. You can do this easily by using the static
`.processEvents()` function on the `QApplication` class. Simply add a
line like the following, somewhere in your
long-running code block:

[source,python]
----
QApplication.processEvents()
----

If we can take our long-running `time.sleep` code and break it down into
multiple steps, we can insert `.processEvents` in between. The code for
this would be:

[source,python]
----
def oh_no(self):
    for n in range(5):
        QApplication.processEvents()
        time.sleep(1)
----

Now when you push the button your code is entered as before. However,
now `QApplication.processEvents()`
intermittently passes control back to Qt, and allows it to respond to
OS events as normal. Qt will now accept
events *and handle them* before returning to run the remainder of your
code.

This works, but it's horrible for a couple of reasons.

Firstly, when you pass control back to Qt, your code is no longer
running. This means that whatever long-running thing you're trying to do
will take *longer*. That is definitely not what you want.

Secondly, processing events outside the main event loop (`app.exec_()`)
causes your application to branch off into handling code (e.g. for
triggered slots, or events) while within your loop. If your code depends
on/responds to external state this can cause undefined behaviour. The
code below demonstrates this in action:

[source,python]
----
include::code/multithreading_2.py[]
----

If you run this code you'll see the counter as before. Pressing
"DANGER!" will change the displayed text to "Pressed", as defined at the
entry point to the `oh_no` function. However, if you press the "?"
button while `oh_no` is still running you'll see that the message
changes. State is being changed from outside your loop.

This is a toy example. However, if you have multiple long-running
processes within your application, with each calling
`QApplication.processEvents()` to keep things ticking, your application
behaviour can be unpredictable.

=== Threads and Processes

If you take a step back and think about what you want to happen in your
application, it can probably be summed up with "stuff to happen at the
same time as other stuff happens".

There are two main approaches to running independent tasks within a PyQt
application: _threads_ and _processes_.

_Threads_ share the same memory space, so are quick to start up and
consume minimal resources. The shared memory makes it trivial to pass
data between threads, however reading/writing memory from different
threads can lead to race conditions or segfaults. In Python there is the
added issue that multiple threads are bound by the same Global
Interpreter Lock (GIL) — meaning non-GIL-releasing Python code can only
execute in one thread at a time. However, this is not a major issue with
PyQt where most of the time is spent outside of Python.

_Processes_ use separate memory space (and an entirely separate Python
interpreter). This side-steps any potential problems with the GIL, but
at the cost of slower start-up times, larger memory overhead and
complexity in sending/receiving data.

For simplicity's sake it usually makes sense to use threads, unless you
have a good reason to use processes (see [caveats](#caveats) later).
Subprocesses in Qt are better suited to running and communicating with
external programs.

=== QRunnable and the QThreadPool

Qt provides a very simple interface for running jobs in other threads,
which is exposed nicely in PyQt. This is built around two classes:
`QRunnable` and `QThreadPool`. The former is the container for the work
you want to perform, while the latter is the method by which you pass
that work to alternate threads.

The neat thing about using `QThreadPool` is that it handles queuing and
execution of workers for you. Other than queuing up jobs and retrieving
the results there is not very much to do at all.

To define a custom `QRunnable` you can subclass the base `QRunnable`
class, then place the code you wish you execute within the `run()`
method. The following is an implementation of our long running
`time.sleep` job as a `QRunnable`. Add the following code to
`multithread.py`, above the `MainWindow` class definition.

[source,python]
----
include::code/multithreading_3.py[]
----

Executing our function in another thread is simply a matter of creating
an instance of the `Worker` and then pass it to our `QThreadPool`
instance and it will be executed automatically.

Next add the following within the `__init__` block, to set up our thread
pool.

[source,python]
----
self.threadpool = QThreadPool()
print("Multithreading with maximum %d threads" % self.threadpool.maxThreadCount())
----

Finally, add the following lines to our `oh_no` function.

[source,python]
----
def oh_no(self):
    worker = Worker()
    self.threadpool.start(worker)
----

Now, clicking on the button will create a worker to handle the
(long-running) process and spin that off into another thread via thread
pool. If there are not enough threads available to process incoming
workers, they'll be queued and executed in order at a later time.

Try it out and you'll see that your application now handles you bashing
the button with no problems.

Check what happens if you hit the button multiple times. You should see
your threads executed immediately *up to* the number reported by
`.maxThreadCount`. If you hit the button again after there are already
this number of active workers, the subsequent workers will be queued
until a thread becomes available.

=== Extended Runners

If you want to pass custom data into the execution function you can set up
your runner to take _arguments_ or _keywords_ and then store the data on
the runner itself. The data will be accessible while running via
`self.` on your `QRunnable` object.

In fact, you can even take advantage of the fact that in Python functions are
objects and pass in the function to execute rather than subclassing each
time. In the following construction we only require a single `Worker` class
to handle all of our execution jobs.

[source,python]
----
include::code/multithreading_4.py[]
----

You can now pass in any Python function and have it executed in a
separate thread.

[source,python]
----
include::code/multithreading_5.py[]
----

=== Thread IO

Sometimes it's helpful to be able to pass back *state* and *data* from
running workers. This could include the outcome of calculations, raised
exceptions or ongoing progress (think progress bars). Qt provides the
*signals and slots* framework which allows you to do just that and is
thread-safe, allowing safe communication directly from running threads
to your GUI frontend. _Signals_ allow you to `.emit` values, which are
then picked up elsewhere in your code by *slot* functions which have
been linked with `.connect`.

Below is a simple `WorkerSignals` class defined to contain a number of
example signals.

NOTE: Custom signals can only be defined on objects derived from
`QObject`. Since `QRunnable` is not derived from `QObject` we can't
define the signals there directly. A custom QObject to hold the
signals is the simplest solution.

[source,python]
----
include::code/multithreading_6.py[]
----

In this example we've defined 5 custom signals:

1. _finished_ signal, with no data to indicate when the task is
complete.
2. _error_ signal which receives a `tuple` of `Exception` type,
`Exception` value and formatted traceback.
3. _result_ signal receiving any `object` type from the executed
function.

You may not find a need for all of these signals, but they are included
to give an indication of what is possible. In the following code we're
going to implement a long-running task that makes use of these signals
to provide useful information to the user.

[source,python]
----
include::code/multithreading_7.py[]
----

You can connect your own handler functions to these signals to receive
notification of completion (or the result) of threads.

[source,python]
----
include::code/multithreading_8.py[]
----

=== QRunnable Examples

The features of `QRunnables` described can be used to build runners
suited for a variety of tasks. Below are some examples for how to
construct runners and applications to use them in a number of different
scenarios.

==== The Updater

You often want to receive progress information information from long-running
threads. This can be done easily defining a signal on the `WorkerSignals` object,
through which you pass a number indicating % completion. The example
below uses this to update a running progress bar.

[source,python]
----
include::code/multithreading_example_updater.py[]
----

.Progress bar showing current progress for a long-running worker.
image::multithreading-example-updater.png[scaledwidth=30%,align="center"]

NOTE: If you want to support variable runners by passing in a function
it will not have access to the progress callback. You can get around this
by passing it into your function directly. See the _Generic Logger_
description below.

==== The Logger

Threading is a good option where you need to run IO operations and
receive the data from them. This can mean interacting with APIs or
websites, or receiving serial data from hardware.

In this example we create multiple runners, each sending back their
data live, tagged with their own identifier. This allows the returning data to
be associated with the runner it has come from, and forwarded to the
correct output.

[source,python]
----
include::code/multithreading_example_logger.py[]
----

If you run this example and press the button you'll see the HTML
output from a number of websites, prepended by the worker ID that
retrieve them. Note that output from different workers is interleaved.

.Logging output from multiple workers to the main window.
image::multithreading-example-logger.png[scaledwidth=30%,align="center"]

The `tuple` is of course optional, you could send back bare strings if
you have only one runner, or don't need to associated outputs with
a source. It is also possible to send a `bytestring`, or any other type
of data, by setting up the signals appropriately.

==== The Generic

If you have multiple similar jobs to run, or the runners have no
specific requirements, a generic runner may be all you need. Pass
in the function to run and receive output, errors and progress.

A complete working example is given below, showcasing the custom
`QRunnable` worker together with the worker & progress signals. You
should be able to easily adapt this code to any
application you develop.

[source,python]
----
include::code/multithreading_example_generic.py[]
----



////

==== Using Python multithreading in PyQt

You may have spotted the slight flaw in this master plan — we are still
making use of the event loop (and the *GUI thread*) to process the
output of our workers.

This isn't a problem when we're simply tracking progress, completion or
returning metadata. However, if you have workers which return large
amounts of data — e.g. loading large files, performing complex analysis
and need (large) results, or querying databases — passing this data back
through the GUI thread may cause performance problems and is best
avoided.

Similarly, if your application makes use of a large number of threads
and Python result handlers, you may come up against the limitations of
the GIL. As mentioned previously, when using threads execution of Python
is limited to a single thread at one time. The Python code that handles
signals from your threads can be blocked by your workers and *vice
versa*. Since blocking your slot functions blocks the event loop, this
can directly impact GUI responsiveness.

In these cases it is often better to use a pure-Python
thread pool (e.g. concurrent futures) implementation to keep your
*processing* and thread-event handling further isolated from your GUI.


////